{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload external packages / modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import run_nerf\n",
    "\n",
    "from load_llff import load_llff_data\n",
    "from load_deepvoxels import load_dv_data\n",
    "from load_blender import load_blender_data\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args:\n",
      "datadir = ./data/nerf_llff_data/fern\n",
      "dataset_type = llff\n",
      "factor = 4\n",
      "\n",
      "no_batching = False\n",
      "i_embed = 0\n",
      "N_samples = 64\n",
      "N_importance = 128\n",
      "use_viewdirs = True\n",
      "lrate_decay = 250\n",
      "\n",
      "llffhold = 8\n",
      "\n",
      "N_rand = 4096\n",
      "loaded args\n",
      "Loaded image data (756, 1008, 3, 20) [ 756.         1008.          815.13158322]\n",
      "Loaded ./data/nerf_llff_data/fern 16.985296178676084 80.00209740336334\n",
      "recentered (3, 5)\n",
      "[[ 1.0000000e+00  1.8605668e-10  7.4923900e-10 -4.4703485e-09]\n",
      " [-1.8605668e-10  1.0000000e+00  7.4923900e-10 -4.4703485e-09]\n",
      " [-7.4923900e-10 -7.4923900e-10  1.0000000e+00 -7.4505807e-10]]\n",
      "Data:\n",
      "(20, 3, 5) (20, 756, 1008, 3) (20, 2)\n",
      "HOLDOUT view is 12\n"
     ]
    }
   ],
   "source": [
    "basedir = './logs'\n",
    "expname = 'fern_example'\n",
    "\n",
    "config = os.path.join(basedir, expname, 'config.txt')\n",
    "print('Args:')\n",
    "print(open(config, 'r').read())\n",
    "parser = run_nerf.config_parser()\n",
    "\n",
    "args = parser.parse_args('--config {} --ft_path {}'.format(config, os.path.join(basedir, expname, 'model_200000.npy')))\n",
    "print('loaded args')\n",
    "\n",
    "images, poses, bds, render_poses, i_test = load_llff_data(args.datadir, args.factor, \n",
    "                                                          recenter=True, bd_factor=.75, \n",
    "                                                          spherify=args.spherify)\n",
    "H, W, focal = poses[0,:3,-1].astype(np.float32)\n",
    "\n",
    "H = int(H)\n",
    "W = int(W)\n",
    "hwf = [H, W, focal]\n",
    "\n",
    "images = images.astype(np.float32)\n",
    "poses = poses.astype(np.float32)\n",
    "\n",
    "if args.no_ndc:\n",
    "    near = tf.reduce_min(bds) * .9\n",
    "    far = tf.reduce_max(bds) * 1.\n",
    "else:\n",
    "    near = 0.\n",
    "    far = 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 63 27 <class 'int'> <class 'int'> True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create nerf model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m _, render_kwargs_test, start, grad_vars, models = \u001b[43mrun_nerf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_nerf\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m bds_dict = {\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnear\u001b[39m\u001b[33m'\u001b[39m : tf.cast(near, tf.float32),\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfar\u001b[39m\u001b[33m'\u001b[39m : tf.cast(far, tf.float32),\n\u001b[32m      7\u001b[39m }\n\u001b[32m      8\u001b[39m render_kwargs_test.update(bds_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/nerf/run_nerf.py:390\u001b[39m, in \u001b[36mcreate_nerf\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    388\u001b[39m output_ch = \u001b[32m4\u001b[39m\n\u001b[32m    389\u001b[39m skips = [\u001b[32m4\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m model = \u001b[43minit_nerf_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mD\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnetdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnetwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ch\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_ch\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_ch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskips\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskips\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ch_views\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ch_views\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_viewdirs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse_viewdirs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    394\u001b[39m grad_vars = model.trainable_variables\n\u001b[32m    395\u001b[39m models = {\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: model}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/nerf/run_nerf_helpers.py:10\u001b[39m, in \u001b[36minit_nerf_model\u001b[39m\u001b[34m(D, W, input_ch, input_ch_views, output_ch, skips, use_viewdirs)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/nerf/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/nerf/.venv/lib/python3.11/site-packages/keras/src/backend/common/keras_tensor.py:194\u001b[39m, in \u001b[36mKerasTensor.__tf_tensor__\u001b[39m\u001b[34m(self, dtype, name)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    195\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    197\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mused when constructing Keras Functional models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    198\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    199\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    200\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand `keras.ops`). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    201\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    210\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    211\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    212\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    213\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    214\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "# Create nerf model\n",
    "_, render_kwargs_test, start, grad_vars, models = run_nerf.create_nerf(args)\n",
    "\n",
    "bds_dict = {\n",
    "    'near' : tf.cast(near, tf.float32),\n",
    "    'far' : tf.cast(far, tf.float32),\n",
    "}\n",
    "render_kwargs_test.update(bds_dict)\n",
    "\n",
    "print('Render kwargs:')\n",
    "pprint.pprint(render_kwargs_test)\n",
    "\n",
    "\n",
    "down = 4\n",
    "render_kwargs_fast = {k : render_kwargs_test[k] for k in render_kwargs_test}\n",
    "render_kwargs_fast['N_importance'] = 0\n",
    "\n",
    "c2w = np.eye(4)[:3,:4].astype(np.float32) # identity pose matrix\n",
    "test = run_nerf.render(H//down, W//down, focal/down, c2w=c2w, **render_kwargs_fast)\n",
    "img = np.clip(test[0],0,1)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8\n",
      "16\n",
      "24\n",
      "32\n",
      "40\n",
      "48\n",
      "56\n",
      "64\n",
      "72\n",
      "80\n",
      "88\n",
      "96\n",
      "104\n",
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (126, 94) to (128, 96) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, saving\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"logs/fern_example/video.mp4\" controls   height=\"320\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down = 8 # trade off resolution+aliasing for render speed to make this video faster\n",
    "frames = []\n",
    "for i, c2w in enumerate(render_poses):\n",
    "    if i%8==0: print(i)\n",
    "    test = run_nerf.render(H//down, W//down, focal/down, c2w=c2w[:3,:4], **render_kwargs_fast)\n",
    "    frames.append((255*np.clip(test[0],0,1)).astype(np.uint8))\n",
    "    \n",
    "print('done, saving')\n",
    "f = 'logs/fern_example/video.mp4'\n",
    "imageio.mimwrite(f, frames, fps=30, quality=8)\n",
    "\n",
    "from IPython.display import Video\n",
    "Video(f, height=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433cdb87f14e4a738c3b1d502431b215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='x', max=1.0, min=-1.0, step=0.01), FloatSlider(valueâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive, widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def f(x, y, z):\n",
    "    \n",
    "    c2w = tf.convert_to_tensor([\n",
    "        [1,0,0,x],\n",
    "        [0,1,0,y],\n",
    "        [0,0,1,z],\n",
    "        [0,0,0,1],\n",
    "    ], dtype=tf.float32)\n",
    "    \n",
    "    test = run_nerf.render(H//down, W//down, focal/down, c2w=c2w, **render_kwargs_fast)\n",
    "    img = np.clip(test[0],0,1)\n",
    "    \n",
    "    plt.figure(2, figsize=(20,6))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "sldr = lambda : widgets.FloatSlider(\n",
    "    value=0.,\n",
    "    min=-1.,\n",
    "    max=1.,\n",
    "    step=.01,\n",
    ")\n",
    "\n",
    "names = ['x', 'y', 'z']\n",
    "    \n",
    "interactive_plot = interactive(f, **{n : sldr() for n in names})\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
